data = read.csv(choose.files())

head(data)
summary(data)

library(ggplot2)
library(gridExtra)
library(dplyr)
library(qqplotr)
library(nnet)

str(data)

# Convert "Diagnosis" into a factor
data$Diagnosis <- as.factor(data$Diagnosis)

# Split the data into training and test sets
set.seed(123)  # For reproducibility
sample <- sample(1:nrow(data), 0.7 * nrow(data))
train_data <- data[sample, ]
test_data <- data[-sample, ]

# Fit a multinomial logistic regression model
model <- multinom(Diagnosis ~ WBC + LYMp + NEUTp + LYMn + NEUTn + RBC + HGB + HCT + MCV + MCH + MCHC + PLT + PDW + PCT, data = train_data)

# Check the summary of the model
summary(model)

# Make predictions on the test set
predicted <- predict(model, newdata = test_data)

# Evaluate the model
confusion_matrix <- table(predicted, test_data$Diagnosis)
print(confusion_matrix)

model1 = lm(Diagnosis ~ ., data = data)





#MODEL LEARNING

install.packages("caret")
library(caret)

data$Diagnosis <- as.factor(data$Diagnosis)

X <- data[, !(names(data) %in% "Diagnosis")]
y <- data$Diagnosis

# Set the seed for reproducibility
set.seed(42)

# Define the partition
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE, times = 1)

# Split the data
X_train <- X[trainIndex, ]
X_test <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]

# Print the number of samples in the training and testing sets
cat("X_train samples:", length(y_train), "\n")
cat("X_test samples:", length(y_test), "\n")


# Install and load necessary packages
install.packages("ggplot2")
library(ggplot2)

summary(model)
model

install.packages("lmtest")
library(nnet)
library(lmtest)

# Likelihood Ratio Test
lr_test <- lrtest(model)

# Wald Test
wald_test <- waldtest(model)


# Print test results
print(lr_test)
print(wald_test)




# Load necessary libraries
install.packages("randomForest")
library(randomForest)

# Convert the Diagnosis column to a factor (since it is categorical)
data$Diagnosis <- as.factor(data$Diagnosis)

# Train the Random Forest classification model
model2 <- randomForest(Diagnosis ~ ., data = data, importance = TRUE)

# Get feature importances
importance_scores <- importance(model2)

# Convert to a data frame for easier plotting
importance_df <- data.frame(Feature = rownames(importance_scores), Importance = importance_scores[, "MeanDecreaseGini"])

# Plot feature importances
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("Feature") +
  ylab("Importance") +
  ggtitle("Feature Importance using Random Forest")





#MODEL BUILDING

# Install required packages if not already installed
install.packages(c("rpart", "extraTrees", "xgboost", "lightgbm", "catboost"))
install.packages("catboost")

library(rpart)         # For Decision Tree
library(randomForest)  # For Random Forest
library(xgboost)       # For XGBoost
library(lightgbm)      # For LightGBM
library(caret)         # For creating confusion matrix and calculating balanced accuracy



X_train <- X[trainIndex, ]
X_test <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]



# Ensure y_pred and y_true have the same levels
ensure_levels <- function(y_pred, y_true) {
  levels(y_pred) <- levels(y_true)
  return(y_pred)
}

# Function to calculate balanced accuracy
balanced_accuracy <- function(y_true, y_pred) {
  y_pred <- ensure_levels(y_pred, y_true)
  cm <- confusionMatrix(y_pred, y_true)
  return(mean(cm$byClass[,"Balanced Accuracy"]))
}

# Initialize models
SEED <- 42
models <- list(
  dt = rpart,
  rf = randomForest
)

# Loop through models
for (name in names(models)) {
  cat(paste0("* ", name, " | "))
  
  # Fit model
  if (name == "dt") {
    model <- models[[name]](y_train ~ ., data = X_train)
    y_pred_train <- predict(model, X_train, type = "class")
    y_pred_test <- predict(model, X_test, type = "class")
  } else if (name == "rf") {
    model <- models[[name]](X_train, y_train, ntree = 100)
    y_pred_train <- predict(model, X_train)
    y_pred_test <- predict(model, X_test)
  }
  
  # Calculate balanced accuracy
  acc_train <- balanced_accuracy(y_train, y_pred_train)
  acc_test <- balanced_accuracy(y_test, y_pred_test)
  cat(sprintf("Acc Train: %.4f | Acc Test: %.4f\n", acc_train, acc_test))
}


# Select numeric columns
features <- data %>% select_if(is.numeric) %>% names()

# Create color palette
colors <- scales::hue_pal()(length(features))

# Create individual plots and store in a list
plots <- list()
for (i in seq_along(features)) {
  p <- ggplot(data, aes_string(x = features[i])) +
    geom_histogram(aes(y = ..density..), fill = NA, color = colors[i], bins = 30) +
    geom_density(fill = colors[i], alpha = 0.4) +
    labs(title = features[i]) +
    theme_light() +
    theme(plot.title = element_text(size = 10, face = "bold"),
          axis.title.x = element_blank())
  plots[[i]] <- p
}

# Arrange plots in a 7x2 grid
grid.arrange(grobs = plots, ncol = 2, nrow = 7)


# Select numeric columns
features <- data %>% select_if(is.numeric) %>% names()

# Create individual Q-Q plots and store in a list
plots <- list()
for (i in seq_along(features)) {
  p <- ggplot(data, aes(sample = !!sym(features[i]))) +
    stat_qq_line() +
    stat_qq_point() +
    labs(title = features[i]) +
    theme_light() +
    theme(plot.title = element_text(size = 10, face = "bold"),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  plots[[i]] <- p
}

# Arrange plots in a 7x2 grid
grid.arrange(grobs = plots, ncol = 4, nrow = 4)


# Create the count plot
plot <- ggplot(data, aes(x = Diagnosis)) +
  geom_bar(fill = "lightblue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5, size = 3, fontface = "bold") +
  labs(x = "", y = "Count", title = "Diagnosis", color = "darkblue", title.fontface = "bold") +
  theme_light()

# Show the plot
print(plot)


features <- names(data) # Assuming all columns are features

# Calculate the correlation matrix using Spearman method
corr_matrix <- cor(data, method = "spearman")

# Convert correlation matrix to long format
corr_matrix_long <- reshape2::melt(corr_matrix)

# Create the heatmap
plot <- ggplot(corr_matrix_long, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "black") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       midpoint = 0, limits = c(-1, 1), name = "Correlation") +
  geom_text(aes(label = round(value, 2)), size = 3, fontface = "bold") +
  theme_minimal() +
  labs(x = "", y = "", title = "Correlation Matrix", color = "black", 
       title.fontface = "bold", fill = "Correlation") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Show the plot
print(plot)


install.packages("reshape2")
# Load necessary libraries
library(ggplot2)
library(reshape2)
library(corrplot)

# Assuming 'data' is your dataset and 'features' is a vector of column names you want to include in the correlation matrix
features <- c("WBC", "LYMp", "NEUTp","LYMn","NEUTn","RBC","HGB","HCT","MCV","MCH","MCHC","PLT","PDW","PCT") # replace with your actual feature names
data_subset <- data[, features]

# Compute the Spearman correlation matrix
corr_matrix <- cor(data_subset, method = "spearman")

# Create a mask for the upper triangle
mask <- upper.tri(corr_matrix)

# Melt the correlation matrix for ggplot2
melted_corr_matrix <- melt(corr_matrix)

# Apply the mask
melted_corr_matrix <- melted_corr_matrix[!mask[lower.tri(mask, diag = TRUE)],]

# Plot the heatmap
ggplot(data = melted_corr_matrix, aes(Var2, Var1, fill = value)) +
  geom_tile(color = "white", size = 1.2) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name = "Spearman\nCorrelation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 8, hjust = 1, face = "bold"),
        axis.text.y = element_text(size = 8, face = "bold"),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(size = 12, face = "bold", color = "black")) +
  labs(title = "Correlation Matrix") +
  geom_text(aes(label = sprintf("%.2f", value)), color = "black", size = 3, fontface = "bold")


# Assuming y_train is already defined from the previous code
# Convert y_train to a data frame for ggplot
df_y_train <- data.frame(Diagnosis = y_train)

# Create the plot
ggplot(data = df_y_train, aes(x = Diagnosis)) +
  geom_bar(aes(y = after_stat(count)), fill = "skyblue", color = "black", width = 0.7) +
  geom_text(stat = 'count', aes(label = after_stat(count)), hjust = -0.1, size = 3, fontface = "bold", color = "black") +
  labs(title = "Diagnosis Train", y = "", x = "") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", color = "darkblue"),
    axis.text.y = element_text(size = 10, face = "bold", color = "black")
  ) +
  coord_flip()  # Flip the coordinates to match the horizontal bar plot

# Perform stepwise selection using AIC as the criterion
stepwise_model <- stepAIC(model, direction = "both")

